---
title: "Logistic regresion, LDA and QDA on Weekly dataset."
output: 
  md_document:
    variant: markdown_github
---

```{r}
options(warn = -1)
library(ISLR)
summary(Weekly)
```
```{r}
plot(Weekly)
```

checking corealationship between variables. Excluding `Direction` which is qualitative.
It appears only `Year` and `Volume` have relationship.

```{r}

cor(Weekly[, -9])
```
```{r}

attach(Weekly)
glm_fit = glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Weekly, family = binomial)
summary(glm_fit)
```

It appears only `Lag2` have some statistical significance.

Now using predict function we can get the probablities. Then we use threshold as 0.5 to predict `Up` and `Down`
```{r}

glm_probs = predict(glm_fit, type = "response")
glm_pred = rep("Down", length(glm_probs))
glm_pred[glm_probs > 0.5] = "Up"
table(glm_pred, Direction)
```

Percentage of currect predictions: (54+557)/(54+557+48+430) = 56.1%.
Weeks the market goes up the logistic regression is right most of the time, 557/(557+48) = 92.1%.
Weeks the market goes up the logistic regression is wrong most of the time 54/(430+54) = 11.2%.

Now we'll fit the trainning data period from 1990 to 2008 using `Lag2` only.
```{r}

train = (Year < 2009)
weekly_testing = Weekly[!train,]
direction_testing = Direction[!train]
glm_fit = glm(Direction ~ Lag2, data = Weekly, family = binomial, subset = train)
glm_probs = predict(glm_fit, weekly_testing, type = "response")
glm_pred = rep("Down", length(glm_probs))
glm_pred[glm_probs > 0.5] = "Up"
table(glm_pred, direction_testing)

```
```{r}
mean(glm_pred == direction_testing)
```

Fitting LDA model.
```{r}

library(MASS)
lda_fit = lda(Direction ~ Lag2, data = Weekly, subset = train)
lda_pred = predict(lda_fit, weekly_testing)
table(lda_pred$class, direction_testing)
```
```{r}

mean(lda_pred$class == direction_testing)
```

Fitting QDA model

```{r}

qda_fit = qda(Direction ~ Lag2, data = Weekly, subset = train)
qda_class = predict(qda_fit, weekly_testing)$class
table(qda_class, direction_testing)

```
```{r}

mean(qda_class == direction_testing)

```

QDA correctness is 58.7%

Now, KNN

```{r}
library(class)
training_data = as.matrix(Lag2[train])
testing_data = as.matrix(Lag2[!train])
direction_training = Direction[train]

set.seed(1)
knn_pred = knn(training_data, testing_data, direction_training, k = 1)
table(knn_pred, direction_testing)

```
```{r}

mean(knn_pred == direction_testing)

```

Logistic regression and LDA provides similar error rates.